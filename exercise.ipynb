{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Description\n",
    "\n",
    "In this question we will be trying to classify emails into spam/ham.\n",
    "\n",
    "Input: \n",
    " 1. A training (train.txt) file containing two '\\t' (tab) separated columns. The first column is either ham or spam, depending on whether the email message is harmless or spam. The second column contains the email contents. Each row is newline separated.\n",
    " 2. A test file (test.txt) containing only email messages separated by newline\n",
    "\n",
    "Output:\n",
    " 1. For each line in test.txt, output \"ham\" or \"spam\" (without quotes). Each line should be newline separated. Please don't print any other characters. For ease of submission, name this file as 'labels.txt'\n",
    " \n",
    "Submission Instructions:\n",
    "You can train on this machine, and generate the test labels as many times as you want, without submitting. When you're ready, please uncomment/run the last cell (with a heading of `submit`). Set the file name, you're trying to submit, and your userID.\n",
    "The score you receive will be updated on the forum, when you refresh.\n",
    "\n",
    "Special Instructions/Warnings:\n",
    "\n",
    "* Please switch off the notebook instance when not using, otherwise you'll be incurring cost out of your allocated budget.\n",
    "* Please don't submit judiciously. The more you submit, the more resources you're using, and the more cost you'd be incurring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model-development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "with open(\"labels.txt\", \"w\") as f:\n",
    "    n = len(open(\"test.txt\", \"r\").readlines())\n",
    "    x = '\\n'.join([\"ham\" if random.random() < 0.5 else \"spam\" for i in range(n)])\n",
    "    f.write(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submitting\n",
    "filename = \"labels.txt\"\n",
    "userID = \"15CS30033\"\n",
    "\n",
    "###################### DONOT EDIT FROM HERE ON #########################\n",
    "#### ANY ATTEMPT AT MODIFYING THIS CODE WILL BE SEVERELY PENALIZED ####\n",
    "import json, requests\n",
    "\n",
    "config = json.load(open('NAIRP_config.json', 'r'))\n",
    "courseID, exerciseID = config['courseID'], config['exerciseID']\n",
    "API_ENDPOINT = \"http://127.0.0.1:5000/evaluate\"\n",
    "data = {\"userID\": userID, \"courseID\": courseID, \"exerciseID\": exerciseID}\n",
    "r = requests.post(url=API_ENDPOINT, params=data, files={'labels': open(filename, 'r')})\n",
    "print(r.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
